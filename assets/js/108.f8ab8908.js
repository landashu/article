(window.webpackJsonp=window.webpackJsonp||[]).push([[108],{583:function(s,t,a){"use strict";a.r(t);var e=a(41),n=Object(e.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("p",[s._v("前面已经教了如何安装伪分布式和分布式，那么接下来就要学习 hadoop 有哪些命令。")]),s._v(" "),a("h2",{attrs:{id:"普通指令"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#普通指令"}},[s._v("#")]),s._v(" 普通指令")]),s._v(" "),a("p",[s._v("创建一个 test 目录")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 hadoop-3.1.3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -mkdir /test")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("查看根目录下有哪些文件")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 hadoop-3.1.3"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -ls /")]),s._v("\nFound "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" items\ndrwxr-xr-x   - root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(":22 /test\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("将 linux 操作系统下的 /home/tmp/biguncle 文件 copy 到 hdfs 的 test 目录下")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 tmp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -put /home/tmp/biguncle /test")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("查看文件被切割几块 (-blocks) 及每块的位置信息 (-locations)")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fsck /test/biguncle -files -blocks -locations")]),s._v("\nConnecting to namenode via http://node113:9870/fsck?ugi"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("root"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("files")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("blocks")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("locations")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("&")]),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("path")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("%2Ftest%2Fbiguncle\nFSCK started by root "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("auth:SIMPLE"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" from /127.0.0.1 "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("for")]),s._v(" path /test/biguncle at Sat May 08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(":50:40 CST "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# biguncle 大小为 0 bytes，副本数为 1，0个块")]),s._v("\n/test/biguncle "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" bytes, replicated: "),a("span",{pre:!0,attrs:{class:"token assign-left variable"}},[s._v("replication")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(", "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" block"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":  OK\n\n\nStatus: HEALTHY\n Number of data-nodes:  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n Number of racks:               "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n Total dirs:                    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Total symlinks:                "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n\nReplicated Blocks:\n Total size:    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" B\n Total files:   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n Total blocks "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Minimally replicated blocks:   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Over-replicated blocks:        "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Under-replicated blocks:       "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Mis-replicated blocks:         "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Default replication factor:    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v("\n Average block replication:     "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0")]),s._v("\n Missing blocks:                "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Corrupt blocks:                "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Missing replicas:              "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n\nErasure Coded Block Groups:\n Total size:    "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" B\n Total files:   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Total block "),a("span",{pre:!0,attrs:{class:"token function"}},[s._v("groups")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("validated"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(":        "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Minimally erasure-coded block groups:  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Over-erasure-coded block groups:       "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Under-erasure-coded block groups:      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Unsatisfactory placement block groups: "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Average block group size:      "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0.0")]),s._v("\n Missing block groups:          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Corrupt block groups:          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\n Missing internal blocks:       "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("\nFSCK ended at Sat May 08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),s._v(":50:40 CST "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("in")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("9")]),s._v(" milliseconds\n\n\nThe filesystem under path "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'/test/biguncle'")]),s._v(" is HEALTHY\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br"),a("span",{staticClass:"line-number"},[s._v("30")]),a("br"),a("span",{staticClass:"line-number"},[s._v("31")]),a("br"),a("span",{staticClass:"line-number"},[s._v("32")]),a("br"),a("span",{staticClass:"line-number"},[s._v("33")]),a("br"),a("span",{staticClass:"line-number"},[s._v("34")]),a("br"),a("span",{staticClass:"line-number"},[s._v("35")]),a("br"),a("span",{staticClass:"line-number"},[s._v("36")]),a("br"),a("span",{staticClass:"line-number"},[s._v("37")]),a("br"),a("span",{staticClass:"line-number"},[s._v("38")]),a("br"),a("span",{staticClass:"line-number"},[s._v("39")]),a("br"),a("span",{staticClass:"line-number"},[s._v("40")]),a("br"),a("span",{staticClass:"line-number"},[s._v("41")]),a("br"),a("span",{staticClass:"line-number"},[s._v("42")]),a("br"),a("span",{staticClass:"line-number"},[s._v("43")]),a("br")])]),a("p",[s._v("将 hdfs 中的 biguncle 文件下载到 linux  的 home 目录下")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -get /test/biguncle /home")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ls")]),s._v("\nbiguncle  tmp\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("删除 hdfs 的 test 目录中的指定文件")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -rm /test/biguncle")]),s._v("\nDeleted /test/biguncle\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("删除 test 目录，但前提是没其他文件")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -rmdir /test")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("删除 test 目录，即使目录里有其他文件")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -rmr /test")]),s._v("\nrmr: DEPRECATED: Please use "),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'-rm -r'")]),s._v(" instead.\nDeleted /test\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br")])]),a("p",[s._v("查看 test 目录下 biguncle 文件")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -cat /test/biguncle")]),s._v("\n我再做一个测试\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("查看 test 目录下 biguncle 文件末尾的数据，默认 10 行")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -tail /test/biguncle")]),s._v("\n我再做一个测试\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br")])]),a("p",[s._v("hadoop 文件移动，或重新名命")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -mv /test/biguncle /test1/bu")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("hadoop 执行一个 jar 文件")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hadoop har xxx.jar\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("hadoop 创建一个空文件，必须再目录下创建")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -touchz /test/bbb.txt")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("将目录下的所有文件合并成一个文件，并下载到 linux")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -ls /test")]),s._v("\nFound "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),s._v(" items\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":19 /test/bbb.txt\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":22 /test/ccc.txt\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":23 /test/ddd.txt\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 home"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -getmerge /test /home/tmp/fff.txt")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 tmp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# ls")]),s._v("\nfff.txt\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br")])]),a("p",[s._v("将目录下的文件 copy 到其他目录")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 tmp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -cp /test/bbb.txt /test1")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("p",[s._v("查看某个文件的大小，也可以查看指定目录")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 tmp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -du /test")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("  /test/bbb.txt\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("  /test/ccc.txt\n"),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("  "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v("  /test/ddd.txt\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br")])]),a("p",[s._v("递归查看目录下所有文件")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("root@node113 tmp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# hadoop fs -lsr /")]),s._v("\ndrwxr-xr-x   - root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":23 /test\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":19 /test/bbb.txt\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":22 /test/ccc.txt\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":23 /test/ddd.txt\ndrwxr-xr-x   - root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":26 /test1\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup          "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":26 /test1/bbb.txt\n-rw-r--r--   "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),s._v(" root supergroup         "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("22")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("2021")]),s._v("-05-08 "),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),s._v(":13 /test1/bu\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br")])]),a("p",[s._v("手动执行 fsimage 文件和 edit 文件合并元数据")]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hadoop dfsadmin -rollEdits\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("h2",{attrs:{id:"知识点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#知识点"}},[s._v("#")]),s._v(" 知识点")]),s._v(" "),a("ol",[a("li",[s._v("当执行格式化指令时，会在指定的目录下，生成 /dfs/name 目录。此目录时 namenode 服务存储元数据的目录。")]),s._v(" "),a("li",[s._v("当格式化后，启动 HDFS 前，会生成一个 fsimage_000000000000000000000 文件")]),s._v(" "),a("li",[s._v("启动后生成 dfs/data 目录，这是 datanode 节点存储数据块的目录。")]),s._v(" "),a("li",[s._v("启动后生成 dfs/name/in_use.lock 这个文件的作用是防止在同一台服务器上启动多个 namenode")]),s._v(" "),a("li",[s._v("启动后生成 dfs/name/current/edits_000000000000000000001-000000000000000000002 等文件，该文件记录了事务的生成。可以用以下命令格式化输出到别的文件查看。")])]),s._v(" "),a("div",{staticClass:"language-shell line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-shell"}},[a("code",[s._v("hdfs oev -i edits_000000000000000000001-000000000000000000002 -o a.xml\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br")])]),a("ol",{attrs:{start:"6"}},[a("li",[s._v("没生成一个新得 Edits 文件，文件中都会以 START LOG 开头，当一个 Edits 文件写完后，会议 END LOG 结尾。即在 START LOG 到"),a("br"),s._v("\n END LOG 存储的是这个 Edits 文件所有的事务记录。")]),s._v(" "),a("li",[s._v("每当 HDFS 接收一个事务操作（mkdir put mv），都会分配事务 ID，然后挟到 Edits 文件中。")]),s._v(" "),a("li",[s._v("启动后生成 dfs/name/current/edits_inprogress_000000000000000000003，只包含了 START LOG，他的作用是记录当前正在执行的事务文件 。后面的编号是以上一次 Txid+1 来名命。")]),s._v(" "),a("li",[s._v("初次使用 HDFS 时，有一个默认的 Edits（edits_inprogress_000000000000000000001）和 Fsimage，他们合并后得到 edits_000000000000000000001-000000000000000000002，合并周期为（1 分钟），以后在使用 HDFS 的过程中，edits_inprogress 合并的条件：1. 达到合并周期 (3600s)，2. 执行手动合并指令，3. 停止 HDFS 在启动 HDFS")]),s._v(" "),a("li",[s._v("上传文件底层会拆分如下事务过程：")])]),s._v(" "),a("ul",[a("li",[s._v("OP_ADD 将文件加入到指定的 HDFS 文件目录下，并以 ._Copyging_结尾，表示此文件还未写完")]),s._v(" "),a("li",[s._v("ALLOCATE_BLOCK_ID 为文件分配块 ID")]),s._v(" "),a("li",[s._v("SET_GENSTAMP_V2 生成时间戳版本号，全局唯一，每一块不同")]),s._v(" "),a("li",[s._v("ADD_BLOCK 写块数据")]),s._v(" "),a("li",[s._v("OP_CLOSE 表示块数据写完")]),s._v(" "),a("li",[s._v("OP_RENAME_OLD 将文件重命名以表示写完")])]),s._v(" "),a("ol",{attrs:{start:"11"}},[a("li",[s._v("当停止 HDFS 在启动 HDFS，执行一个新事物后，会触发 END LOG 事务，生成新得 Edits 文件。")]),s._v(" "),a("li",[s._v("seen_txid 记录最新 edits_inprogress 的事务 ID")]),s._v(" "),a("li",[s._v("Fsimage_N 文件存储的 N 号事务前的所有元数据信息")]),s._v(" "),a("li",[s._v("Fsimage_N.md5 存储的是 Fsimage 的校验和")])]),s._v(" "),a("h2",{attrs:{id:"fsimage介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#fsimage介绍"}},[s._v("#")]),s._v(" Fsimage 介绍")]),s._v(" "),a("p",[s._v("把文件和目录的元数据信息持久地存储到 fsimage 文件中，每次启动时从中将元数据加载到内存中构建目录结构树，之后的操作记录在 edits log 中，定期将 edits log 与 fsimage 合并刷到 fsimage 中。")]),s._v(" "),a("p",[s._v("loadFSimage (File curFile) 用于从 fsimage 中读入 namenode 持久化的信息。fsimage 中保存的元数据信息格式如下，hdfs 加载和写入时都按照该格式进行。")]),s._v(" "),a("ul",[a("li",[s._v("imageVersion：Fsimage 文件的版本号，每生成一个新得 Fsimage 文件，就会有一个版本号")]),s._v(" "),a("li",[s._v("NameSpaceID：namenode 的名命空间 id，用于表示 namenode，每当执行一次格式化命令时，就会生成新的。")]),s._v(" "),a("li",[s._v("NumFiles：整个 HDFS 存储的文件数")]),s._v(" "),a("li",[s._v("genStamp：目录创建的时间戳，块生成的时间戳")]),s._v(" "),a("li",[s._v("path：文件路径")]),s._v(" "),a("li",[s._v("BlockNums：文件的块的数量")]),s._v(" "),a("li",[s._v("mtime：上传时间")]),s._v(" "),a("li",[s._v("atime：访问时间")]),s._v(" "),a("li",[s._v("BlockID：块编号")]),s._v(" "),a("li",[s._v("BlockSize：切块大小 (128M)")]),s._v(" "),a("li",[s._v("BlockNumBytes：块实际大小")]),s._v(" "),a("li",[s._v("StorgeInfo：块存储的 datanode 节点信息")]),s._v(" "),a("li",[s._v("nsquota：目录的名命空间大小配额，默认是 - 1 表示目录可以无限制存储")]),s._v(" "),a("li",[s._v("dsquota：目录的磁盘空间存储配额，默认是 - 1")]),s._v(" "),a("li",[s._v("username：目录的创建者")]),s._v(" "),a("li",[s._v("groupname：目录的所属组")]),s._v(" "),a("li",[s._v("permission：目录的权限")])]),s._v(" "),a("p",[s._v("fsimage 是一个二进制文件，当中记录了 HDFS 中所有文件和目录的元数据信息。")]),s._v(" "),a("p",[s._v("HDFS 启动时，会将这些信息读入内存之后，构建一个文件目录结构树，将表示文件或目录的节点填入到结构中。")]),s._v(" "),a("h2",{attrs:{id:"md5校验"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#md5校验"}},[s._v("#")]),s._v(" MD5 校验")]),s._v(" "),a("p",[s._v("MD5 校验和（checksum）通过对接收的传输数据执行散列运算来检查数据的正确性。")]),s._v(" "),a("p",[s._v("一个 MD5 校验和 通过对接收的传输数据执行散列运算来检查数据的正确性。计算出的散列值拿来和随数据传输的散列值比较。如果两个值相同，说明传输的数据完整无误、没有被篡改过（前提是散列值没有被篡改），从而可以放心使用。")])])}),[],!1,null,null,null);t.default=n.exports}}]);