---
title: Hive Sqoop安装及指令
date: 2023-06-25 09:22:36
permalink:  /hive/56
sidebar: true
article: false #  是否未非文章页，非文章不显示 面包屑和作者、时间，不显示最近更新栏，不会参与到最近更新文章的数据计算中
comment: false #  评论区
editLink: false
---

> 本文及后续所有文章都以3.1.2做为版本讲解和入门学习

## Sqoop介绍
Sqoop 是apache提供的工具，用于HDFS和关系数据库之间数据导入和导出，可以从HDFS导出数据到关系型数据库，也可以从关系型数据库导入数据到HDFS。

## 安装
```shell
wget https://mirrors.tuna.tsinghua.edu.cn/apache/sqoop/1.4.7/sqoop-1.4.7.bin__hadoop-2.6.0.tar.gz
```
必须配置jdk、hadoop环境变量，因为sqoop在使用是会去找环境变量对应的路径，从而工作。最好把sqoop自己也加如到环境变量中。

需要将连接的数据库的驱动包加如sqoop/server/lib目录下。

配置 sqoop2的话要允许访问 HDFS，但是我是sqoop1.
```xml
  <property>
    <name>hadoop.proxyuser.sqoop2.hosts</name>
    <value>*</value>
  </property>
  <property>
    <name>hadoop.proxyuser.sqoop2.groups</name>
    <value>*</value>
  </property>
```

## Sqoop命令
查看mysql所有数据库
```shell
sqoop list-databases --connect jdbc:mysql://node113:3306/?useSSL=false -username root -password Admin@123
```
查看指定数据库下的所有表
```shell
sqoop list-tables --connect jdbc:mysql://node113:3306/hive?useSSL=false -username root -password Admin@123
```
将关系型数据库（test库，test_01表）导入到HDFS 的 '/sqoop/test_01'  目录下，并以 ' ' 空格分割列，sqoop会在hadoop自动创建目录和文件
```shell
sqoop import --connect jdbc:mysql://node113:3306/test?useSSL=false -username root -password Admin@123 --table test_01 --target-dir '/sqoop/test_01' --fields-terminated-by ' ' -m 1;
```
将HDFS数据导入导出到关系型数据库，sqoop只能导出数据，不能自动建表，所以在导出之前表就要建好。
```shell
sqoop export --connect jdbc:mysql://node113:3306/test?useSSL=false -username root -password Admin@123 --export-dir '/sqoop/test_01/part-m-00000' --table test_02 -m 1 --fields-terminated-by ' '
```