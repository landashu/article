---
title: Flume 日志收集系统介绍及安装
date: 2023-06-25 09:22:36
permalink:  /flume/1
sidebar: true
article: false #  是否未非文章页，非文章不显示 面包屑和作者、时间，不显示最近更新栏，不会参与到最近更新文章的数据计算中
comment: false #  评论区
editLink: false
---

> 本文及后续所有文章都以1.8.0做为版本讲解和入门学习

## 什么是 Flume

![](/assets/img/flume/1/img.png)

Flume是由Cloudera软件公司提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统，后与2009年被捐赠了apache软件基金会，为hadoop相关组件之一。尤其近几年随着flume的不断被完善以及升级版本的逐一推出，特别是flume-ng;同时flume内部的各种组件不断丰富，用户在开发的过程中使用的便利性得到很大的改善，现已成为apache top项目之一。

apache Flume 是一个从可以收集例如日志，事件等数据资源，并将这些数量庞大的数据从各项数据资源中集中起来存储的工具/服务。flume具有高可用，分布式，配置工具，其设计的原理也是基于将数据流，如日志数据从各种网站服务器上汇集起来存储到HDFS，HBase等集中存储器中。

## Flume特点
1、可靠性：当节点出现故障时，日志能够被传送到其他节点上而不会丢失。Flume提供了三种级别的可靠性保障，所有的数据以event为单位传输，从强到弱依次分别为：end-to-end（收到数据agent首先将event写到磁盘上，当数据传送成功后，再删除；如果数据发送失败，可以重新发送。），Store on failure（这也是scribe采用的策略，当数据接收方crash时，将数据写到本地，待恢复后，继续发送），Best effort（数据发送到接收方后，不会进行确认）。

2、可扩展性：Flume采用了三层架构，分别为agent，collector和storage，每一层均可以水平扩展。其中，所有agent和collector由master统一管理，这使得系统容易监控和维护，且master允许有多个（使用ZooKeeper进行管理和负载均衡），这就避免了单点故障问题。

3、可管理性：所有agent和colletor由master统一管理，这使得系统便于维护。多master情况，Flume利用ZooKeeper和gossip，保证动态配置数据的一致性。用户可以在master上查看各个数据源或者数据流执行情况，且可以对各个数据源配置和动态加载。Flume提供了web 和shell script command两种形式对数据流进行管理。

4、功能可扩展性：用户可以根据需要添加自己的agent，collector或者storage。此外，Flume自带了很多组件，包括各种agent（file， syslog等），collector和storage（file，HDFS等）。

5、文档丰富，社区活跃：Flume 已经成为 Hadoop 生态系统的标配，它的文档比较丰富，社区比较活跃，方便我们学习。


## 基本概念

![](/assets/img/flume/1/img_1.png)


### Event
* Event 是Flume数据传输的基本单元，是数据，如果输入的是文本文件，event是一行记录。
* Flume 以事件(Event )的形式将数据从源头传输到最终的目的。
* Event 由可选的 header 和载有数据的一个 byte array 构成。
  载有的数据对Flume是不透明的。
  Header 是容纳了key-value字符串对的无序集合，key在集合内是唯一的。
  Header 可以在上下文路由中使用扩展。

### source
* Source负责接收event或通过特殊机制产生event，并将events批量的放到一个或多个Channel。
* Source包含event驱动和轮询两种类型。
* Source 有不同的类型。
  与系统集成的Source：Syslog，NetCat。
  自动生成事件的Source：Exec用于Agent和Agent之间的通信的IPC Source：Avro、Thrift。
* Source必须至少和一个Channel关联。

### channel
* Channel位于Source和Sink之间，用于缓存进来的event。
* 当Sink成功的将event发送到下一跳的Channel或最终目的地，event才Channel中移除。
* 不同的Channel提供的持久化水平也是不一样的：
  Memory Channel：volatile。
  File Channel：基于WAL实现。
  JDBC Channel：基于嵌入Database实现。
* Channel支持事物，提供较弱的顺序保证。
* Channel可以和任何数量的Source和Sink工作。

### Sink
* Sink负责将event传输到下一跳或最终目的，成功完成后将event从Channel移除。
* 有不同类型的Sink：
  存储event到最终目的的终端Sink。比如HDFS，HBase。
  自动消耗的Sink。比如：Null Sink。
  用于Agent间通信的IPC sink：Avro。

## 安装
```shell
wget http://archive.apache.org/dist/flume/1.8.0/apache-flume-1.8.0-bin.tar.gz
```
### 部署视图

![](/assets/img/flume/1/img_2.png)

### 文件修改
在 /opt/software/flume-1.8.0/conf/source-netcat.conf 添加该文件，并添加如下内容
```properties
# a1 代表一个flume 给每个组件匿名
a1.sources=r1
a1.channels=c1
a1.sinks=s1

# 指定source 的数据来源以及堆外开放的端口
a1.sources.r1.type=netcat
a1.sources.r1.bind=node113
a1.sources.r1.port=8888

# 指定a1的channels基于内存
a1.channels.c1.type=memory
# 指定a1的sinks 输出到控制台
a1.sinks.s1.type=logger

# 绑定a1 sources和channle 的关系
a1.sources.r1.channels=c1
# 绑定a1 sinks 和 channel 的关系
a1.sinks.s1.channel=c1
```

### 把flume添加到环境变量
```shell
export FLUME_HOME=/opt/software/flume-1.8.0
export PATH=$PATH:$FLUME_HOME/bin
export FLUME_HOME
```

### 启动
```shell
flume-ng agent -n a1 -c /opt/software/flume-1.8.0/conf -f /opt/software/flume-1.8.0/conf/source-netcat.conf -Dflume.root.logger=INFO,console
```
* agent 运行一个flume
* \- n a1 的名称，要和配置文件里面的一样
* \-c 代表配置文件在那个目录
* \- f 代表具体的配置文件路径
* \-Dflume.root.logger 设置一个JAVA系统属性值，常见的  -Dflume.root.logger=INFO,console

### 测试
node103 发送消息
```shell
[root@node103 ~]# nc node113 8888
hello world
OK
```
node113 收到
```shell
2021-05-17 16:40:18,381 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: { headers:{} body: 68 65 6C 6C 6F 20 77 6F 72 6C 64                hello world }
```




