---
title: Hadoop 指令
date: 2023-06-25 09:22:36
permalink:  /hadoop/2
sidebar: true
article: false #  是否未非文章页，非文章不显示 面包屑和作者、时间，不显示最近更新栏，不会参与到最近更新文章的数据计算中
comment: false #  评论区
editLink: false
---

前面已经教了如何安装伪分布式和分布式，那么接下来就要学习 hadoop 有哪些命令。

## 普通指令

创建一个 test 目录
```shell
[root@node113 hadoop-3.1.3]# hadoop fs -mkdir /test
```

查看根目录下有哪些文件
```shell
[root@node113 hadoop-3.1.3]# hadoop fs -ls /
Found 1 items
drwxr-xr-x   - root supergroup          0 2021-05-08 13:22 /test
```

将 linux 操作系统下的 /home/tmp/biguncle 文件 copy 到 hdfs 的 test 目录下
```shell
[root@node113 tmp]# hadoop fs -put /home/tmp/biguncle /test
```

查看文件被切割几块(-blocks)及每块的位置信息(-locations)
```shell
[root@node113 home]# hadoop fsck /test/biguncle -files -blocks -locations
Connecting to namenode via http://node113:9870/fsck?ugi=root&files=1&blocks=1&locations=1&path=%2Ftest%2Fbiguncle
FSCK started by root (auth:SIMPLE) from /127.0.0.1 for path /test/biguncle at Sat May 08 13:50:40 CST 2021
# biguncle 大小为 0 bytes，副本数为 1，0个块
/test/biguncle 0 bytes, replicated: replication=1, 0 block(s):  OK


Status: HEALTHY
 Number of data-nodes:  1
 Number of racks:               1
 Total dirs:                    0
 Total symlinks:                0

Replicated Blocks:
 Total size:    0 B
 Total files:   1
 Total blocks (validated):      0
 Minimally replicated blocks:   0
 Over-replicated blocks:        0
 Under-replicated blocks:       0
 Mis-replicated blocks:         0
 Default replication factor:    1
 Average block replication:     0.0
 Missing blocks:                0
 Corrupt blocks:                0
 Missing replicas:              0

Erasure Coded Block Groups:
 Total size:    0 B
 Total files:   0
 Total block groups (validated):        0
 Minimally erasure-coded block groups:  0
 Over-erasure-coded block groups:       0
 Under-erasure-coded block groups:      0
 Unsatisfactory placement block groups: 0
 Average block group size:      0.0
 Missing block groups:          0
 Corrupt block groups:          0
 Missing internal blocks:       0
FSCK ended at Sat May 08 13:50:40 CST 2021 in 9 milliseconds


The filesystem under path '/test/biguncle' is HEALTHY
```

将 hdfs 中的 biguncle 文件下载到 linux  的home目录下
```shell
[root@node113 home]# hadoop fs -get /test/biguncle /home
[root@node113 home]# ls
biguncle  tmp
```


删除 hdfs 的 test 目录中的指定文件
```shell
[root@node113 home]# hadoop fs -rm /test/biguncle
Deleted /test/biguncle
```

删除 test 目录，但前提是没其他文件
```shell
[root@node113 home]# hadoop fs -rmdir /test
```

删除 test 目录，即使目录里有其他文件
```shell
[root@node113 home]# hadoop fs -rmr /test
rmr: DEPRECATED: Please use '-rm -r' instead.
Deleted /test
```

查看 test 目录下 biguncle 文件
```shell
[root@node113 home]# hadoop fs -cat /test/biguncle
我再做一个测试
```

查看 test 目录下 biguncle 文件末尾的数据，默认10行
```shell
[root@node113 home]# hadoop fs -tail /test/biguncle
我再做一个测试
```

hadoop 文件移动，或重新名命
```shell
[root@node113 home]# hadoop fs -mv /test/biguncle /test1/bu
```

hadoop 执行一个 jar 文件
```shell
hadoop har xxx.jar
```

hadoop 创建一个空文件，必须再目录下创建
```shell
[root@node113 home]# hadoop fs -touchz /test/bbb.txt
```

将目录下的所有文件合并成一个文件，并下载到 linux
```shell
[root@node113 home]# hadoop fs -ls /test
Found 3 items
-rw-r--r--   1 root supergroup          0 2021-05-08 14:19 /test/bbb.txt
-rw-r--r--   1 root supergroup          0 2021-05-08 14:22 /test/ccc.txt
-rw-r--r--   1 root supergroup          0 2021-05-08 14:23 /test/ddd.txt
[root@node113 home]# hadoop fs -getmerge /test /home/tmp/fff.txt
[root@node113 tmp]# ls
fff.txt
```

将目录下的文件 copy 到其他目录
```shell
[root@node113 tmp]# hadoop fs -cp /test/bbb.txt /test1
```

查看某个文件的大小，也可以查看指定目录
```shell
[root@node113 tmp]# hadoop fs -du /test
0  0  /test/bbb.txt
0  0  /test/ccc.txt
0  0  /test/ddd.txt
```
递归查看目录下所有文件
```shell
[root@node113 tmp]# hadoop fs -lsr /
drwxr-xr-x   - root supergroup          0 2021-05-08 14:23 /test
-rw-r--r--   1 root supergroup          0 2021-05-08 14:19 /test/bbb.txt
-rw-r--r--   1 root supergroup          0 2021-05-08 14:22 /test/ccc.txt
-rw-r--r--   1 root supergroup          0 2021-05-08 14:23 /test/ddd.txt
drwxr-xr-x   - root supergroup          0 2021-05-08 14:26 /test1
-rw-r--r--   1 root supergroup          0 2021-05-08 14:26 /test1/bbb.txt
-rw-r--r--   1 root supergroup         22 2021-05-08 14:13 /test1/bu
```

手动执行 fsimage 文件和 edit 文件合并元数据
```shell
hadoop dfsadmin -rollEdits
```

## 知识点
1. 当执行格式化指令时，会在指定的目录下，生成 /dfs/name 目录。此目录时 namenode 服务存储元数据的目录。
2. 当格式化后，启动 HDFS 前，会生成一个 fsimage_000000000000000000000 文件
3. 启动后生成 dfs/data 目录，这是 datanode 节点存储数据块的目录。
4. 启动后生成 dfs/name/in_use.lock 这个文件的作用是防止在同一台服务器上启动多个 namenode
5. 启动后生成 dfs/name/current/edits_000000000000000000001-000000000000000000002 等文件，该文件记录了事务的生成。可以用以下命令格式化输出到别的文件查看。
```shell
hdfs oev -i edits_000000000000000000001-000000000000000000002 -o a.xml
```
6. 没生成一个新得Edits文件，文件中都会以START LOG开头，当一个Edits文件写完后，会议END LOG结尾。即在START LOG 到
   END LOG 存储的是这个Edits 文件所有的事务记录。
7. 每当HDFS接收一个事务操作（mkdir put mv），都会分配事务ID，然后挟到Edits文件中。
8. 启动后生成 dfs/name/current/edits_inprogress_000000000000000000003，只包含了START LOG，他的作用是记录当前正在执行的事务文件 。后面的编号是以上一次Txid+1来名命。
9. 初次使用HDFS时，有一个默认的Edits（edits_inprogress_000000000000000000001）和Fsimage，他们合并后得到edits_000000000000000000001-000000000000000000002，合并周期为（1分钟），以后在使用HDFS的过程中，edits_inprogress合并的条件：1.达到合并周期(3600s)，2. 执行手动合并指令，3. 停止HDFS在启动HDFS
10. 上传文件底层会拆分如下事务过程：
* OP_ADD 将文件加入到指定的HDFS文件目录下，并以 ._Copyging_结尾，表示此文件还未写完
* ALLOCATE_BLOCK_ID 为文件分配块ID
* SET_GENSTAMP_V2 生成时间戳版本号，全局唯一，每一块不同
* ADD_BLOCK 写块数据
* OP_CLOSE 表示块数据写完
* OP_RENAME_OLD 将文件重命名以表示写完
11. 当停止HDFS在启动HDFS，执行一个新事物后，会触发END LOG事务，生成新得Edits文件。
12. seen_txid 记录最新 edits_inprogress 的事务ID
13. Fsimage_N 文件存储的N号事务前的所有元数据信息
14. Fsimage_N.md5 存储的是Fsimage的校验和

## Fsimage介绍
把文件和目录的元数据信息持久地存储到fsimage文件中，每次启动时从中将元数据加载到内存中构建目录结构树，之后的操作记录在edits log中，定期将edits log与fsimage合并刷到fsimage中。

loadFSimage(File curFile)用于从fsimage中读入namenode持久化的信息。fsimage中保存的元数据信息格式如下，hdfs加载和写入时都按照该格式进行。
* imageVersion：Fsimage 文件的版本号，每生成一个新得Fsimage文件，就会有一个版本号
* NameSpaceID：namenode的名命空间id，用于表示namenode，每当执行一次格式化命令时，就会生成新的。
* NumFiles：整个HDFS存储的文件数
* genStamp：目录创建的时间戳，块生成的时间戳
* path：文件路径
* BlockNums：文件的块的数量
* mtime：上传时间
* atime：访问时间
* BlockID：块编号
* BlockSize：切块大小(128M)
* BlockNumBytes：块实际大小
* StorgeInfo：块存储的datanode节点信息
* nsquota：目录的名命空间大小配额，默认是-1 表示目录可以无限制存储
* dsquota：目录的磁盘空间存储配额，默认是-1
* username：目录的创建者
* groupname：目录的所属组
* permission：目录的权限


fsimage是一个二进制文件，当中记录了HDFS中所有文件和目录的元数据信息。

HDFS启动时，会将这些信息读入内存之后，构建一个文件目录结构树，将表示文件或目录的节点填入到结构中。

## MD5校验
MD5 校验和（checksum）通过对接收的传输数据执行散列运算来检查数据的正确性。

一个MD5校验和 通过对接收的传输数据执行散列运算来检查数据的正确性。计算出的散列值拿来和随数据传输的散列值比较。如果两个值相同，说明传输的数据完整无误、没有被篡改过（前提是散列值没有被篡改），从而可以放心使用。