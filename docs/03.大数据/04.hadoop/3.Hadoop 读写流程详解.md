---
title: Hadoop 读写流程详解
date: 2023-06-25 09:22:36
permalink:  /hadoop/3
sidebar: true
article: false #  是否未非文章页，非文章不显示 面包屑和作者、时间，不显示最近更新栏，不会参与到最近更新文章的数据计算中
comment: false #  评论区
editLink: false
---

## 读文件流程

![](/assets/img/hadoop/3/img.png)

1. 客户端向namenode发起Open File请求，目的是获取要下载文件的输入流。namenode收到请求会后会检查路径的合法性，以及客户端的权限。
2. 客户端发起Open File的同时，还会掉用 GetBlockLocation。当第一次的检验通过之后，namenode会将文件的块信息(元数据)封装到输入流，交给客户端。
3.4. 客户端用输入流，根据元数据信息去找指定的datanode读取文件块(按 blockid 顺序读取)
5. 文件下载完成后关闭。

## 上传文件流程

![](/assets/img/hadoop/3/img_1.png)

1. 客户端发起create file，目的是获取HDFS文件的输出流。namenode收到请求后会检测路径的合法性，以及权限。原生hadoop管理是很不完善的，工作中中用的是CDH(商业版hadoop)。如果检测通过，namenode会为这个文件生成块的元数据，比如：
* 为文件切块
* 分配块id
* 分配每个块存在哪个datanode上
  然后将元数据封装到输出流中，返回给客户端。
2.3. client拿到输出流之后，采用PipeLine（数据流管道）机制做数据的上传（发送），这样设计的目的在于利用每台服务器的带宽，最小化推送数据的延迟，减少client带宽的发送。线性模式下，每台机器所有的出口带宽用于以最快的速度传输数据，而不是在多个接收者之间分配带宽。packet，是客户端把文件块打散成一个个的数据包发送。用的是全双通信，边收边发。
4.5. 每台datanode收到packet后，会向上游datanode做ack确认，如果接收失败，会进行重发（重发机制）
6. 当一个文件上传完之后，关闭流。

## 删除文件流程

![](/assets/img/hadoop/3/img_2.png)

1. 当客户端发起一个删除指令，这个指令会传给namenode
2. namenode收到指令，做路径和权限校验，如果检验通过，会将对应的文件信息从内存里删除。此时，文件数据并不是马上就从集群被删除。
3. datanode向namenode发送心跳时(默认时3s周期)，会领取删除指令没然后从磁盘上将文件删除。